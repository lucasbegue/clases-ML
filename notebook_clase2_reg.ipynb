{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPWhgh+XkWHnbt7A/TWYddK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lucasbegue/clases-ML/blob/main/notebook_clase2_reg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Librerias"
      ],
      "metadata": {
        "id": "E1ueRW0pJQzS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tratamiento de datos\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Gráficos\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import style\n",
        "import seaborn as sns\n",
        "\n",
        "# Preprocesado y modelado\n",
        "from scipy.stats import pearsonr\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn.linear_model import RidgeCV\n",
        "from sklearn.linear_model import LassoCV\n",
        "from sklearn.linear_model import ElasticNetCV\n",
        "\n",
        "# Configuración matplotlib\n",
        "plt.rcParams['image.cmap'] = \"bwr\"\n",
        "#plt.rcParams['figure.dpi'] = \"100\"\n",
        "plt.rcParams['savefig.bbox'] = \"tight\"\n",
        "style.use('ggplot') or plt.style.use('ggplot')\n",
        "\n",
        "# Configuración warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "EvUt0cdTJUVL"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Datos"
      ],
      "metadata": {
        "id": "gjoq6YM1JZs5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Descargar el archivo 'meatspec.csv' de la carpeta 'datasets' del drive. Despues subirlo a esta notebook.\n",
        "\n",
        "\n",
        "El departamento de calidad de una empresa de alimentación se encarga de medir el contenido en grasa de la carne que comercializa. El proceso de medición de grasa es costoso en tiempo y recursos. Una alternativa que permitiría reducir costos y tiempo es emplear un espectrofotómetro (instrumento capaz de detectar la absorbancia que tiene un material a diferentes tipos de luz) e inferir el contenido en grasa a partir de sus medidas.\n",
        "\n",
        "Antes de dar por válida esta nueva técnica, la empresa necesita comprobar qué margen de error tiene respecto al análisis químico. Para ello, se mide el espectro de absorbancia a 100 longitudes de onda en 215 muestras de carne, cuyo contenido en grasa se obtiene también por análisis químico, y se entrena un modelo con el objetivo de predecir el contenido en grasa a partir de los valores dados por el espectrofotómetro."
      ],
      "metadata": {
        "id": "Aat0s8DoDK3P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Datos\n",
        "df = pd.read_csv('/content/meatspec.csv')\n",
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "X1AWfE52GMSe",
        "outputId": "bfea278a-4b0a-427a-b636-833ffe771814"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-7010f9f1aea3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Datos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/meatspec.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/meatspec.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "9NOYy3gCG9Li"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Relación entre variables"
      ],
      "metadata": {
        "id": "K_cBZQ43I6-4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corr_matrix = df.select_dtypes(include=['float64', 'int']).corr(method='pearson')\n",
        "\n",
        "# Heatmap matriz de correlaciones\n",
        "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(6, 6))\n",
        "\n",
        "sns.heatmap(\n",
        "    corr_matrix, square=True, ax=ax\n",
        ")\n",
        "ax.tick_params(labelsize=3)"
      ],
      "metadata": {
        "id": "j4IxPVC6Jz6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vemos que las variables estan todas muy correlacionadas entre sí. En general se observan correlaciones absolutas >0.9, lo que implica un problema para modelos de regresión lineal. "
      ],
      "metadata": {
        "id": "8M29LfoqDvta"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelos"
      ],
      "metadata": {
        "id": "zx-sw5KpKYjZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# División de los datos en train y test\n",
        "X = df.drop(columns='fat')\n",
        "y = df['fat']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y.values.reshape(-1,1),\n",
        "    train_size=0.7,\n",
        "    random_state=23,\n",
        "    shuffle=True\n",
        ")"
      ],
      "metadata": {
        "id": "zIYoikCoKMFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mínimos cuadrados (OLS)"
      ],
      "metadata": {
        "id": "2N0oW7Y9K-F9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creación y entrenamiento del modelo\n",
        "modelo = LinearRegression(normalize=True)\n",
        "modelo.fit(X=X_train, y=y_train)\n",
        "LinearRegression(normalize=True)\n",
        "\n",
        "# Coeficientes del modelo\n",
        "df_coeficientes = pd.DataFrame(\n",
        "    {\n",
        "     'predictor': ['intersecto'] + list(X_train.columns.values),\n",
        "     'coef': [modelo.intercept_] + list(modelo.coef_.flatten())\n",
        "    }\n",
        ")\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(11, 3.84))\n",
        "ax.stem(df_coeficientes.predictor, df_coeficientes.coef, markerfmt=' ')\n",
        "plt.xticks(rotation=90, ha='right', size=5)\n",
        "ax.set_xlabel('variable')\n",
        "ax.set_ylabel('coeficientes')\n",
        "ax.set_title('Coeficientes del modelo')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uSeFI5fBK85L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicciones test\n",
        "y_pred = modelo.predict(X=X_test)\n",
        "y_pred = y_pred.flatten()\n",
        "\n",
        "# Error de test del modelo \n",
        "rmse_ols = mean_squared_error(\n",
        "    y_true  = y_test,\n",
        "    y_pred  = y_pred,\n",
        "    squared = False\n",
        ")\n",
        "\n",
        "print(f\"El error (rmse) de test es: {rmse_ols}\")"
      ],
      "metadata": {
        "id": "YKLvoVIOLj57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ridge"
      ],
      "metadata": {
        "id": "DSoo1a6-TIHM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creación y entrenamiento del modelo (con búsqueda por CV del valor óptimo alpha)\n",
        "modelo = RidgeCV(\n",
        "    alphas = np.logspace(-10, 2, 200), # prueba 200 valores en el intervalo [10^-10; 10^2]\n",
        "    fit_intercept = True,\n",
        "    normalize = True,\n",
        "    store_cv_values = True\n",
        ")\n",
        "\n",
        "_ = modelo.fit(X = X_train, y = y_train)"
      ],
      "metadata": {
        "id": "njtZzGzrTW-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cuando utilizamos regularización, es interesante analizar cómo los coeficientes se acercan a cero cuando incrementamos alpha. "
      ],
      "metadata": {
        "id": "Z1nQgCeBUhjf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evolución de los coeficientes en función de alpha\n",
        "\n",
        "alphas = modelo.alphas\n",
        "coefs = []\n",
        "\n",
        "for alpha in alphas:\n",
        "  modelo_temp = Ridge(alpha=alpha, fit_intercept=False, normalize=True)\n",
        "  modelo_temp.fit(X_train, y_train)\n",
        "  coefs.append(modelo_temp.coef_.flatten())\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(7, 3.84))\n",
        "ax.plot(alphas, coefs)\n",
        "ax.set_xscale('log')\n",
        "ax.set_xlabel('alpha')\n",
        "ax.set_ylabel('coeficientes')\n",
        "ax.set_title('Coeficientes del modelo en función de la regularización');\n",
        "plt.axis('tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AYdKGtDxUgAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evolución del error en función de alpha\n",
        "# modelo.cv_values_ almacena el mse de cv para cada valor de alpha.\n",
        "# Tiene dimensiones (n_samples, n_targets, n_alphas)\n",
        "mse_cv = modelo.cv_values_.reshape((-1, 200)).mean(axis=0) # mse promedio en las 150 observaciones\n",
        "mse_sd = modelo.cv_values_.reshape((-1, 200)).std(axis=0)  # desvio estandar de mse\n",
        "\n",
        "# Se aplica la raíz cuadrada para pasar de mse a rmse\n",
        "rmse_cv = np.sqrt(mse_cv)\n",
        "rmse_sd = np.sqrt(mse_sd)\n",
        "\n",
        "# Se identifica el óptimo y el óptimo + 1std\n",
        "min_rmse = np.min(rmse_cv)\n",
        "sd_min_rmse = rmse_sd[np.argmin(rmse_cv)]\n",
        "optimo = modelo.alphas[np.argmin(rmse_cv)]\n",
        "\n",
        "# Gráfico del error +- 1 desviación estándar\n",
        "fig, ax = plt.subplots(figsize=(7, 3.84))\n",
        "ax.plot(modelo.alphas, rmse_cv)\n",
        "ax.fill_between(\n",
        "    modelo.alphas,\n",
        "    rmse_cv + rmse_sd,\n",
        "    rmse_cv - rmse_sd,\n",
        "    alpha=0.2\n",
        ")\n",
        "\n",
        "ax.axvline(\n",
        "    x=optimo,\n",
        "    c=\"gray\",\n",
        "    linestyle='--',\n",
        "    label='óptimo'\n",
        ")\n",
        "\n",
        "ax.set_xscale('log')\n",
        "ax.set_ylim([0, None])\n",
        "ax.set_title('Evolución del error CV en función de la regularización')\n",
        "ax.set_xlabel('alpha')\n",
        "ax.set_ylabel('RMSE')\n",
        "plt.legend(loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VL3HXk3-Ub13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mejor valor alpha encontrado\n",
        "print(f\"Mejor valor de alpha encontrado: {modelo.alpha_}\")"
      ],
      "metadata": {
        "id": "5UnWewWvfb4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicciones test\n",
        "y_pred = modelo.predict(X=X_test)\n",
        "y_pred = y_pred.flatten()\n",
        "\n",
        "# Error de test del modelo \n",
        "rmse_ridge = mean_squared_error(\n",
        "    y_true = y_test,\n",
        "    y_pred = y_pred,\n",
        "    squared = False\n",
        ")\n",
        "\n",
        "print(\"\")\n",
        "print(f\"El error (rmse) de test es: {rmse_ridge}\")"
      ],
      "metadata": {
        "id": "XpcsCkx_bClG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Lasso"
      ],
      "metadata": {
        "id": "8shiTLG-i81a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La regularización Lasso penaliza la suma del valor absolutos de los coeficientes de regresión. A esta penalización se le conoce como l1 y tiene el efecto de forzar a que los coeficientes de los predictores tiendan a cero. Dado que un predictor con coeficiente de regresión cero no influye en el modelo, lasso consigue excluir los predictores menos relevantes. El grado de penalización está controlado por el hiperparámetro alpha. Cuando alpha=0 el resultado es equivalente al de un modelo lineal por mínimos cuadrados ordinarios. A medida que alpha aumenta, mayor es la penalización y más predictores quedan excluidos."
      ],
      "metadata": {
        "id": "A-5-QNL_NkUU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creación y entrenamiento del modelo (con búsqueda por CV del valor óptimo alpha)\n",
        "# Por defecto LassoCV utiliza el mean squared error\n",
        "modelo = LassoCV(\n",
        "    alphas = np.logspace(-10, 3, 200),\n",
        "    normalize = True,\n",
        "    cv = 10\n",
        ")\n",
        "_ = modelo.fit(X=X_train, y=y_train)"
      ],
      "metadata": {
        "id": "RRzTxt0RMeF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evolución de los coeficientes en función de alpha\n",
        "alphas = modelo.alphas_\n",
        "coefs = []\n",
        "\n",
        "for alpha in alphas:\n",
        "    modelo_temp = Lasso(alpha=alpha, fit_intercept=False, normalize=True)\n",
        "    modelo_temp.fit(X_train, y_train)\n",
        "    coefs.append(modelo_temp.coef_.flatten())\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(7, 3.84))\n",
        "ax.plot(alphas, coefs)\n",
        "ax.set_xscale('log')\n",
        "ax.set_ylim([-15,None])\n",
        "ax.set_xlabel('alpha')\n",
        "ax.set_ylabel('coeficientes')\n",
        "ax.set_title('Coeficientes del modelo en función de la regularización');"
      ],
      "metadata": {
        "id": "O_R5VumMM0bn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Número de predictores incluidos (coeficiente !=0) en función de alpha\n",
        "alphas = modelo.alphas_\n",
        "n_predictores = []\n",
        "\n",
        "for alpha in alphas:\n",
        "    modelo_temp = Lasso(alpha=alpha, fit_intercept=False, normalize=True)\n",
        "    modelo_temp.fit(X_train, y_train)\n",
        "    coef_no_cero = np.sum(modelo_temp.coef_.flatten() != 0)\n",
        "    n_predictores.append(coef_no_cero)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(7, 3.84))\n",
        "ax.plot(alphas, n_predictores)\n",
        "ax.set_xscale('log')\n",
        "ax.set_ylim([-15,None])\n",
        "ax.set_xlabel('alpha')\n",
        "ax.set_ylabel('nº predictores')\n",
        "ax.set_title('Predictores incluidos en función de la regularización');"
      ],
      "metadata": {
        "id": "DBt4HQSnNXRu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evolución del error en función de alpha\n",
        "# modelo.mse_path_ almacena el mse de cv para cada valor de alpha\n",
        "# Tiene dimensiones (n_alphas, n_folds)\n",
        "mse_cv = modelo.mse_path_.mean(axis=1)\n",
        "mse_sd = modelo.mse_path_.std(axis=1)\n",
        "\n",
        "# Se aplica la raíz cuadrada para pasar de mse a rmse\n",
        "rmse_cv = np.sqrt(mse_cv)\n",
        "rmse_sd = np.sqrt(mse_sd)\n",
        "\n",
        "# Se identifica el óptimo y el óptimo + 1std\n",
        "min_rmse     = np.min(rmse_cv)\n",
        "sd_min_rmse  = rmse_sd[np.argmin(rmse_cv)]\n",
        "optimo       = modelo.alphas_[np.argmin(rmse_cv)]\n",
        "\n",
        "# Gráfico del error +- 1 desviación estándar\n",
        "fig, ax = plt.subplots(figsize=(7, 3.84))\n",
        "ax.plot(modelo.alphas_, rmse_cv)\n",
        "ax.fill_between(\n",
        "    modelo.alphas_,\n",
        "    rmse_cv + rmse_sd,\n",
        "    rmse_cv - rmse_sd,\n",
        "    alpha=0.2\n",
        ")\n",
        "\n",
        "ax.axvline(\n",
        "    x = optimo,\n",
        "    c = \"gray\",\n",
        "    linestyle = '--',\n",
        "    label = 'óptimo'\n",
        ")\n",
        "\n",
        "ax.set_xscale('log')\n",
        "ax.set_ylim([0,None])\n",
        "ax.set_title('Evolución del error CV en función de la regularización')\n",
        "ax.set_xlabel('alpha')\n",
        "ax.set_ylabel('RMSE')\n",
        "plt.legend();"
      ],
      "metadata": {
        "id": "W4OJX9MNOB8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mejor valor alpha encontrado\n",
        "print(f\"Mejor valor de alpha encontrado: {modelo.alpha_}\")"
      ],
      "metadata": {
        "id": "xIOPm0RMOJgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = modelo.predict(X=X_test)\n",
        "y_pred = y_pred.flatten()\n",
        "\n",
        "# Error de test del modelo \n",
        "rmse_lasso = mean_squared_error(\n",
        "    y_true = y_test,\n",
        "    y_pred = y_pred,\n",
        "    squared = False\n",
        ")\n",
        "\n",
        "print(\"\")\n",
        "print(f\"El error (rmse) de test es: {rmse_lasso}\")"
      ],
      "metadata": {
        "id": "KX1sGJiARwQ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Elastic Net"
      ],
      "metadata": {
        "id": "MAeMe9o7VTAe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creación y entrenamiento del modelo (con búsqueda por CV del valor óptimo alpha)\n",
        "# Por defecto ElasticNetCV utiliza el mean squared error\n",
        "modelo = ElasticNetCV(\n",
        "    l1_ratio = [0, 0.1, 0.5, 0.7, 0.9, 0.95, 0.99],\n",
        "    alphas = np.logspace(-10, 3, 200),\n",
        "    normalize = True,\n",
        "    cv = 10\n",
        ")\n",
        "\n",
        "_ = modelo.fit(X = X_train, y = y_train)"
      ],
      "metadata": {
        "id": "nDBzpDKhVb2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evolución del error en función de alpha y l1_ratio\n",
        "# modelo.mse_path_ almacena el mse de cv para cada valor de alpha y l1_ratio.\n",
        "# Tiene dimensiones (n_l1_ratio, n_alpha, n_folds)\n",
        "\n",
        "# Error medio de las 10 particiones por cada valor de alpha y l1_ratio \n",
        "mean_error_cv = modelo.mse_path_.mean(axis =2)\n",
        "\n",
        "# El resultado es un array de dimensiones (n_l1_ratio, n_alpha)\n",
        "# Se convierte en un dataframe\n",
        "df_resultados_cv = pd.DataFrame(\n",
        "                        data   = mean_error_cv.flatten(),\n",
        "                        index  = pd.MultiIndex.from_product(\n",
        "                                    iterables = [modelo.l1_ratio, modelo.alphas_],\n",
        "                                    names     = ['l1_ratio', 'modelo.alphas_']\n",
        "                                 ),\n",
        "                        columns = [\"mse_cv\"]\n",
        "                    )\n",
        "\n",
        "df_resultados_cv['rmse_cv'] = np.sqrt(df_resultados_cv['mse_cv'])\n",
        "df_resultados_cv = df_resultados_cv.reset_index().sort_values('mse_cv', ascending = True)\n",
        "df_resultados_cv"
      ],
      "metadata": {
        "id": "s16nEHUYEV8X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}